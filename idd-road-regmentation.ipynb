{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"UhGVcnMbgr7y"},"source":["# ENet -  Real Time Semantic Segmentation\n","\n","In this notebook, we have reproduced the ENet paper. <br/>\n","Link to the paper: https://arxiv.org/pdf/1606.02147.pdf <br/>\n","Link to the repository: https://github.com/iArunava/ENet-Real-Time-Semantic-Segmentation\n","\n","\n","Star and Fork!\n","\n","\n","**ALL THE CODE IN THIS NOTEBOOK ASSUMES THE USAGE OF THE <span style=\"color:blue;\">CAMVID</span> DATASET**"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"8qnyf_pzhKXv"},"source":["## Install the dependencies and Import them"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{},"colab_type":"code","execution":{"iopub.execute_input":"2024-01-11T14:32:04.449955Z","iopub.status.busy":"2024-01-11T14:32:04.449158Z","iopub.status.idle":"2024-01-11T14:32:06.091569Z","shell.execute_reply":"2024-01-11T14:32:06.090759Z","shell.execute_reply.started":"2024-01-11T14:32:04.449921Z"},"id":"5NCTHdEqj317","trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from torch.optim.lr_scheduler import StepLR\n","import cv2\n","import os\n","from tqdm import tqdm\n","import torch.optim.lr_scheduler as lr_scheduler\n","from PIL import Image"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7m-TI5tHhSka"},"source":["## Download the CamVid dataset "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"i26TZVXmhewY"},"source":["## Create the ENet model\n","\n","We decided to to split the model to three sub classes:\n","\n","1) Initial block  \n","\n","2) RDDNeck - class for regular, downsampling and dilated bottlenecks\n","\n","3) ASNeck -  class for asymetric bottlenecks\n","\n","4) UBNeck - class for upsampling bottlenecks"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{},"colab_type":"code","execution":{"iopub.execute_input":"2024-01-11T14:32:06.093532Z","iopub.status.busy":"2024-01-11T14:32:06.093149Z","iopub.status.idle":"2024-01-11T14:32:06.101050Z","shell.execute_reply":"2024-01-11T14:32:06.100196Z","shell.execute_reply.started":"2024-01-11T14:32:06.093506Z"},"id":"kqHUezLfPBwn","trusted":true},"outputs":[],"source":["class InitialBlock(nn.Module):\n","  \n","  # Initial block of the model:\n","  #         Input\n","  #        /     \\\n","  #       /       \\\n","  #maxpool2d    conv2d-3x3\n","  #       \\       /  \n","  #        \\     /\n","  #      concatenate\n","   \n","    def __init__ (self,in_channels = 3,out_channels = 13):\n","        super().__init__()\n","\n","\n","        self.maxpool = nn.MaxPool2d(kernel_size=2, \n","                                      stride = 2, \n","                                      padding = 0)\n","\n","        self.conv = nn.Conv2d(in_channels, \n","                                out_channels,\n","                                kernel_size = 3,\n","                                stride = 2, \n","                                padding = 1)\n","\n","        self.prelu = nn.PReLU(16)\n","\n","        self.batchnorm = nn.BatchNorm2d(out_channels)\n","  \n","    def forward(self, x):\n","        \n","        main = self.conv(x)\n","        main = self.batchnorm(main)\n","        \n","        side = self.maxpool(x)\n","        \n","        # concatenating on the channels axis\n","        x = torch.cat((main, side), dim=1)\n","        x = self.prelu(x)\n","        \n","        return x"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{},"colab_type":"code","execution":{"iopub.execute_input":"2024-01-11T14:32:06.102410Z","iopub.status.busy":"2024-01-11T14:32:06.102131Z","iopub.status.idle":"2024-01-11T14:32:06.120123Z","shell.execute_reply":"2024-01-11T14:32:06.119259Z","shell.execute_reply.started":"2024-01-11T14:32:06.102387Z"},"id":"ERqXRpl_sfSE","trusted":true},"outputs":[],"source":["class UBNeck(nn.Module):\n","    \n","  # Upsampling bottleneck:\n","  #     Bottleneck Input\n","  #        /        \\\n","  #       /          \\\n","  # conv2d-1x1     convTrans2d-1x1\n","  #      |             | PReLU\n","  #      |         convTrans2d-3x3\n","  #      |             | PReLU\n","  #      |         convTrans2d-1x1\n","  #      |             |\n","  # maxunpool2d    Regularizer\n","  #       \\           /  \n","  #        \\         /\n","  #      Summing + PReLU\n","  #\n","  #  Params: \n","  #  projection_ratio - ratio between input and output channels\n","  #  relu - if True: relu used as the activation function else: Prelu us used\n","  \n","    def __init__(self, in_channels, out_channels, relu=False, projection_ratio=4):\n","        \n","        super().__init__()\n","        \n","        # Define class variables\n","        self.in_channels = in_channels\n","        self.reduced_depth = int(in_channels / projection_ratio)\n","        self.out_channels = out_channels\n","        \n","        \n","        if relu:\n","            activation = nn.ReLU()\n","        else:\n","            activation = nn.PReLU()\n","        \n","        self.unpool = nn.MaxUnpool2d(kernel_size = 2,\n","                                     stride = 2)\n","        \n","        self.main_conv = nn.Conv2d(in_channels = self.in_channels,\n","                                    out_channels = self.out_channels,\n","                                    kernel_size = 1)\n","        \n","        self.dropout = nn.Dropout2d(p=0.1)\n","        \n","        \n","        self.convt1 = nn.ConvTranspose2d(in_channels = self.in_channels,\n","                               out_channels = self.reduced_depth,\n","                               kernel_size = 1,\n","                               padding = 0,\n","                               bias = False)\n","        \n","        \n","        self.prelu1 = activation\n","        \n","        # This layer used for Upsampling\n","        self.convt2 = nn.ConvTranspose2d(in_channels = self.reduced_depth,\n","                                  out_channels = self.reduced_depth,\n","                                  kernel_size = 3,\n","                                  stride = 2,\n","                                  padding = 1,\n","                                  output_padding = 1,\n","                                  bias = False)\n","        \n","        self.prelu2 = activation\n","        \n","        self.convt3 = nn.ConvTranspose2d(in_channels = self.reduced_depth,\n","                                  out_channels = self.out_channels,\n","                                  kernel_size = 1,\n","                                  padding = 0,\n","                                  bias = False)\n","        \n","        self.prelu3 = activation\n","        \n","        self.batchnorm = nn.BatchNorm2d(self.reduced_depth)\n","        self.batchnorm2 = nn.BatchNorm2d(self.out_channels)\n","        \n","    def forward(self, x, indices):\n","        x_copy = x\n","        \n","        # Side Branch\n","        x = self.convt1(x)\n","        x = self.batchnorm(x)\n","        x = self.prelu1(x)\n","        \n","        x = self.convt2(x)\n","        x = self.batchnorm(x)\n","        x = self.prelu2(x)\n","        \n","        x = self.convt3(x)\n","        x = self.batchnorm2(x)\n","        \n","        x = self.dropout(x)\n","        \n","        # Main Branch\n","        \n","        x_copy = self.main_conv(x_copy)\n","        x_copy = self.unpool(x_copy, indices, output_size=x.size())\n","        \n","        # summing the main and side branches\n","        x = x + x_copy\n","        x = self.prelu3(x)\n","        \n","        return x"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{},"colab_type":"code","execution":{"iopub.execute_input":"2024-01-11T14:32:06.121517Z","iopub.status.busy":"2024-01-11T14:32:06.121266Z","iopub.status.idle":"2024-01-11T14:32:06.139308Z","shell.execute_reply":"2024-01-11T14:32:06.138538Z","shell.execute_reply.started":"2024-01-11T14:32:06.121487Z"},"id":"r-nTIAS9bd9z","trusted":true},"outputs":[],"source":["class RDDNeck(nn.Module):\n","    def __init__(self, dilation, in_channels, out_channels, down_flag, relu=False, projection_ratio=4, p=0.1):\n","      \n","  # Regular|Dilated|Downsampling bottlenecks:\n","  #\n","  #     Bottleneck Input\n","  #        /        \\\n","  #       /          \\\n","  # maxpooling2d   conv2d-1x1\n","  #      |             | PReLU\n","  #      |         conv2d-3x3\n","  #      |             | PReLU\n","  #      |         conv2d-1x1\n","  #      |             |\n","  #  Padding2d     Regularizer\n","  #       \\           /  \n","  #        \\         /\n","  #      Summing + PReLU\n","  #\n","  # Params: \n","  #  dilation (bool) - if True: creating dilation bottleneck\n","  #  down_flag (bool) - if True: creating downsampling bottleneck\n","  #  projection_ratio - ratio between input and output channels\n","  #  relu - if True: relu used as the activation function else: Prelu us used\n","  #  p - dropout ratio\n","        \n","        super().__init__()\n","        \n","        # Define class variables\n","        self.in_channels = in_channels\n","        \n","        self.out_channels = out_channels\n","        self.dilation = dilation\n","        self.down_flag = down_flag\n","        \n","        # calculating the number of reduced channels\n","        if down_flag:\n","            self.stride = 2\n","            self.reduced_depth = int(in_channels // projection_ratio)\n","        else:\n","            self.stride = 1\n","            self.reduced_depth = int(out_channels // projection_ratio)\n","        \n","        if relu:\n","            activation = nn.ReLU()\n","        else:\n","            activation = nn.PReLU()\n","        \n","        self.maxpool = nn.MaxPool2d(kernel_size = 2,\n","                                      stride = 2,\n","                                      padding = 0, return_indices=True)\n","        \n","\n","        \n","        self.dropout = nn.Dropout2d(p=p)\n","\n","        self.conv1 = nn.Conv2d(in_channels = self.in_channels,\n","                               out_channels = self.reduced_depth,\n","                               kernel_size = 1,\n","                               stride = 1,\n","                               padding = 0,\n","                               bias = False,\n","                               dilation = 1)\n","        \n","        self.prelu1 = activation\n","        \n","        self.conv2 = nn.Conv2d(in_channels = self.reduced_depth,\n","                                  out_channels = self.reduced_depth,\n","                                  kernel_size = 3,\n","                                  stride = self.stride,\n","                                  padding = self.dilation,\n","                                  bias = True,\n","                                  dilation = self.dilation)\n","                                  \n","        self.prelu2 = activation\n","        \n","        self.conv3 = nn.Conv2d(in_channels = self.reduced_depth,\n","                                  out_channels = self.out_channels,\n","                                  kernel_size = 1,\n","                                  stride = 1,\n","                                  padding = 0,\n","                                  bias = False,\n","                                  dilation = 1)\n","        \n","        self.prelu3 = activation\n","        \n","        self.batchnorm = nn.BatchNorm2d(self.reduced_depth)\n","        self.batchnorm2 = nn.BatchNorm2d(self.out_channels)\n","        \n","        \n","    def forward(self, x):\n","        \n","        bs = x.size()[0]\n","        x_copy = x\n","        \n","        # Side Branch\n","        x = self.conv1(x)\n","        x = self.batchnorm(x)\n","        x = self.prelu1(x)\n","        \n","        x = self.conv2(x)\n","        x = self.batchnorm(x)\n","        x = self.prelu2(x)\n","        \n","        x = self.conv3(x)\n","        x = self.batchnorm2(x)\n","                \n","        x = self.dropout(x)\n","        \n","        # Main Branch\n","        if self.down_flag:\n","            x_copy, indices = self.maxpool(x_copy)\n","          \n","        if self.in_channels != self.out_channels:\n","            out_shape = self.out_channels - self.in_channels\n","            \n","            #padding and concatenating in order to match the channels axis of the side and main branches\n","            extras = torch.zeros((bs, out_shape, x.shape[2], x.shape[3]))\n","            if torch.cuda.is_available():\n","                extras = extras.cuda()\n","            x_copy = torch.cat((x_copy, extras), dim = 1)\n","\n","        # Summing main and side branches\n","        x = x + x_copy\n","        x = self.prelu3(x)\n","        \n","        if self.down_flag:\n","            return x, indices\n","        else:\n","            return x"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{},"colab_type":"code","execution":{"iopub.execute_input":"2024-01-11T14:32:06.141958Z","iopub.status.busy":"2024-01-11T14:32:06.141675Z","iopub.status.idle":"2024-01-11T14:32:06.157561Z","shell.execute_reply":"2024-01-11T14:32:06.156744Z","shell.execute_reply.started":"2024-01-11T14:32:06.141936Z"},"id":"tb_i1sCvtmMF","trusted":true},"outputs":[],"source":["class ASNeck(nn.Module):\n","    def __init__(self, in_channels, out_channels, projection_ratio=4):\n","      \n","  # Asymetric bottleneck:\n","  #\n","  #     Bottleneck Input\n","  #        /        \\\n","  #       /          \\\n","  #      |         conv2d-1x1\n","  #      |             | PReLU\n","  #      |         conv2d-1x5\n","  #      |             |\n","  #      |         conv2d-5x1\n","  #      |             | PReLU\n","  #      |         conv2d-1x1\n","  #      |             |\n","  #  Padding2d     Regularizer\n","  #       \\           /  \n","  #        \\         /\n","  #      Summing + PReLU\n","  #\n","  # Params:    \n","  #  projection_ratio - ratio between input and output channels\n","        \n","        super().__init__()\n","        \n","        # Define class variables\n","        self.in_channels = in_channels\n","        self.reduced_depth = int(in_channels / projection_ratio)\n","        self.out_channels = out_channels\n","        \n","        self.dropout = nn.Dropout2d(p=0.1)\n","        \n","        self.conv1 = nn.Conv2d(in_channels = self.in_channels,\n","                               out_channels = self.reduced_depth,\n","                               kernel_size = 1,\n","                               stride = 1,\n","                               padding = 0,\n","                               bias = False)\n","        \n","        self.prelu1 = nn.PReLU()\n","        \n","        self.conv21 = nn.Conv2d(in_channels = self.reduced_depth,\n","                                  out_channels = self.reduced_depth,\n","                                  kernel_size = (1, 5),\n","                                  stride = 1,\n","                                  padding = (0, 2),\n","                                  bias = False)\n","        \n","        self.conv22 = nn.Conv2d(in_channels = self.reduced_depth,\n","                                  out_channels = self.reduced_depth,\n","                                  kernel_size = (5, 1),\n","                                  stride = 1,\n","                                  padding = (2, 0),\n","                                  bias = False)\n","        \n","        self.prelu2 = nn.PReLU()\n","        \n","        self.conv3 = nn.Conv2d(in_channels = self.reduced_depth,\n","                                  out_channels = self.out_channels,\n","                                  kernel_size = 1,\n","                                  stride = 1,\n","                                  padding = 0,\n","                                  bias = False)\n","        \n","        self.prelu3 = nn.PReLU()\n","        \n","        self.batchnorm = nn.BatchNorm2d(self.reduced_depth)\n","        self.batchnorm2 = nn.BatchNorm2d(self.out_channels)\n","        \n","    def forward(self, x):\n","        bs = x.size()[0]\n","        x_copy = x\n","        \n","        # Side Branch\n","        x = self.conv1(x)\n","        x = self.batchnorm(x)\n","        x = self.prelu1(x)\n","        \n","        x = self.conv21(x)\n","        x = self.conv22(x)\n","        x = self.batchnorm(x)\n","        x = self.prelu2(x)\n","        \n","        x = self.conv3(x)\n","                \n","        x = self.dropout(x)\n","        x = self.batchnorm2(x)\n","        \n","        # Main Branch\n","        \n","        if self.in_channels != self.out_channels:\n","            out_shape = self.out_channels - self.in_channels\n","            \n","            #padding and concatenating in order to match the channels axis of the side and main branches\n","            extras = torch.zeros((bs, out_shape, x.shape[2], x.shape[3]))\n","            if torch.cuda.is_available():\n","                extras = extras.cuda()\n","            x_copy = torch.cat((x_copy, extras), dim = 1)\n","        \n","        # Summing main and side branches\n","        x = x + x_copy\n","        x = self.prelu3(x)\n","        \n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class encoder(nn.Module):\n","    def __init__(self, C):\n","        super().__init__()\n","        \n","        # Define class variables\n","        # C - number of classes\n","        self.C = C\n","        \n","        # The initial block\n","        self.init = InitialBlock()\n","        \n","        \n","        # The first bottleneck\n","        self.b10 = RDDNeck(dilation=1, \n","                           in_channels=16, \n","                           out_channels=64, \n","                           down_flag=True, \n","                           p=0.01)\n","        \n","        self.b11 = RDDNeck(dilation=1, \n","                           in_channels=64, \n","                           out_channels=64, \n","                           down_flag=False, \n","                           p=0.01)\n","        \n","        self.b12 = RDDNeck(dilation=1, \n","                           in_channels=64, \n","                           out_channels=64, \n","                           down_flag=False, \n","                           p=0.01)\n","        \n","        self.b13 = RDDNeck(dilation=1, \n","                           in_channels=64, \n","                           out_channels=64, \n","                           down_flag=False, \n","                           p=0.01)\n","        \n","        self.b14 = RDDNeck(dilation=1, \n","                           in_channels=64, \n","                           out_channels=64, \n","                           down_flag=False, \n","                           p=0.01)\n","        \n","        \n","        # The second bottleneck\n","        self.b20 = RDDNeck(dilation=1, \n","                           in_channels=64, \n","                           out_channels=128, \n","                           down_flag=True)\n","        \n","        self.b21 = RDDNeck(dilation=1, \n","                           in_channels=128, \n","                           out_channels=128, \n","                           down_flag=False)\n","        \n","        self.b22 = RDDNeck(dilation=2, \n","                           in_channels=128, \n","                           out_channels=128, \n","                           down_flag=False)\n","        \n","        self.b23 = ASNeck(in_channels=128, \n","                          out_channels=128)\n","        \n","        self.b24 = RDDNeck(dilation=4, \n","                           in_channels=128, \n","                           out_channels=128, \n","                           down_flag=False)\n","        \n","        self.b25 = RDDNeck(dilation=1, \n","                           in_channels=128, \n","                           out_channels=128, \n","                           down_flag=False)\n","        \n","        self.b26 = RDDNeck(dilation=8, \n","                           in_channels=128, \n","                           out_channels=128, \n","                           down_flag=False)\n","        \n","        self.b27 = ASNeck(in_channels=128, \n","                          out_channels=128)\n","        \n","        self.b28 = RDDNeck(dilation=16, \n","                           in_channels=128, \n","                           out_channels=128, \n","                           down_flag=False)\n","        \n","        \n","        # The third bottleneck\n","        self.b31 = RDDNeck(dilation=1, \n","                           in_channels=128, \n","                           out_channels=128, \n","                           down_flag=False)\n","        \n","        self.b32 = RDDNeck(dilation=2, \n","                           in_channels=128, \n","                           out_channels=128, \n","                           down_flag=False)\n","        \n","        self.b33 = ASNeck(in_channels=128, \n","                          out_channels=128)\n","        \n","        self.b34 = RDDNeck(dilation=4, \n","                           in_channels=128, \n","                           out_channels=128, \n","                           down_flag=False)\n","        \n","        self.b35 = RDDNeck(dilation=1, \n","                           in_channels=128, \n","                           out_channels=128, \n","                           down_flag=False)\n","        \n","        self.b36 = RDDNeck(dilation=8, \n","                           in_channels=128, \n","                           out_channels=128, \n","                           down_flag=False)\n","        \n","        self.b37 = ASNeck(in_channels=128, \n","                          out_channels=128)\n","        \n","        self.b38 = RDDNeck(dilation=16, \n","                           in_channels=128, \n","                           out_channels=128, \n","                           down_flag=False)\n","        \n","    def forward(self, x):\n","        \n","        # The initial block\n","        x = self.init(x)\n","        \n","        # The first bottleneck\n","        x, i1 = self.b10(x)\n","        x = self.b11(x)\n","        x = self.b12(x)\n","        x = self.b13(x)\n","        x = self.b14(x)\n","        \n","        # The second bottleneck\n","        x, i2 = self.b20(x)\n","        x = self.b21(x)\n","        x = self.b22(x)\n","        x = self.b23(x)\n","        x = self.b24(x)\n","        x = self.b25(x)\n","        x = self.b26(x)\n","        x = self.b27(x)\n","        x = self.b28(x)\n","        \n","        # The third bottleneck\n","        x = self.b31(x)\n","        x = self.b32(x)\n","        x = self.b33(x)\n","        x = self.b34(x)\n","        x = self.b35(x)\n","        x = self.b36(x)\n","        x = self.b37(x)\n","        x = self.b38(x)\n","\n","        return x, i1,i2\n","        \n","        "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class decoder(nn.Module):\n","    def __init__(self, C):\n","        super().__init__()\n","        \n","        # Define class variables\n","        # C - number of classes\n","        self.C = C\n","\n","        # The fourth bottleneck\n","        self.b40 = UBNeck(in_channels=128, \n","                          out_channels=64, \n","                          relu=True)\n","        \n","        self.b41 = RDDNeck(dilation=1, \n","                           in_channels=64, \n","                           out_channels=64, \n","                           down_flag=False, \n","                           relu=True)\n","        \n","        self.b42 = RDDNeck(dilation=1, \n","                           in_channels=64, \n","                           out_channels=64, \n","                           down_flag=False, \n","                           relu=True)\n","        \n","        \n","        # The fifth bottleneck\n","        self.b50 = UBNeck(in_channels=64, \n","                          out_channels=16, \n","                          relu=True)\n","        \n","        self.b51 = RDDNeck(dilation=1, \n","                           in_channels=16, \n","                           out_channels=16, \n","                           down_flag=False, \n","                           relu=True)\n","        \n","        \n","        # Final ConvTranspose Layer\n","        self.fullconv = nn.ConvTranspose2d(in_channels=16, \n","                                           out_channels=self.C, \n","                                           kernel_size=3, \n","                                           stride=2, \n","                                           padding=1, \n","                                           output_padding=1,\n","                                           bias=False)\n","        \n","    def forward(self, x, i1, i2):\n","        # The fourth bottleneck\n","        x = self.b40(x, i2)\n","        x = self.b41(x)\n","        x = self.b42(x)\n","        \n","        # The fifth bottleneck\n","        x = self.b50(x, i1)\n","        x = self.b51(x)\n","        \n","        # Final ConvTranspose Layer\n","        x = self.fullconv(x)\n","        \n","        \n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class ENet(nn.Module):\n","  \n","  # Creating Enet model!\n","  \n","    def __init__(self, C):\n","        super().__init__()\n","        \n","        self.encoder = encoder(C)\n","        \n","        # Create the decoder\n","        self.decoder = decoder(C)\n","\n","    def forward(self, x):\n","        # Pass input through the encoder\n","        encoder_output, i1, i2 = self.encoder(x)\n","\n","        # Pass encoder output and intermediate feature maps to the decoder\n","        decoder_output = self.decoder(encoder_output, i1, i2)\n","\n","        return decoder_output\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Jg1Rnb3uhnxR"},"source":["## Instantiate the ENet model"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"W5kaK6CnhwG_"},"source":["Move the model to cuda if available"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{},"colab_type":"code","execution":{"iopub.execute_input":"2024-01-11T14:32:06.184959Z","iopub.status.busy":"2024-01-11T14:32:06.184691Z","iopub.status.idle":"2024-01-11T14:32:06.448409Z","shell.execute_reply":"2024-01-11T14:32:06.447401Z","shell.execute_reply.started":"2024-01-11T14:32:06.184937Z"},"id":"lZcgE-F_hvxX","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda:0\n"]}],"source":["# Checking if there is any gpu available and pass the model to gpu or cpu\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","enet = ENet(2)\n","enet = enet.to(device)\n","\n","print(device)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"EvURoRuSlyvP"},"source":["## Define the loader that will load the input and output images"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{},"colab_type":"code","execution":{"iopub.execute_input":"2024-01-11T14:32:06.450103Z","iopub.status.busy":"2024-01-11T14:32:06.449756Z","iopub.status.idle":"2024-01-11T14:32:06.460822Z","shell.execute_reply":"2024-01-11T14:32:06.459664Z","shell.execute_reply.started":"2024-01-11T14:32:06.450074Z"},"id":"XFCIsDF2bpQx","trusted":true},"outputs":[],"source":["def loader(training_path, segmented_path, batch_size, h=512, w=512):\n","    filenames_t = os.listdir(training_path)\n","    total_files_t = len(filenames_t)\n","    \n","    filenames_s = os.listdir(segmented_path)\n","    total_files_s = len(filenames_s)\n","    \n","    assert(total_files_t == total_files_s)\n","    \n","    if str(batch_size).lower() == 'all':\n","        batch_size = total_files_s\n","    \n","    road_idx = 0\n","    while(1):\n","        batch_idxs = np.random.randint(0, total_files_s, batch_size)\n","            \n","        inputs = []\n","        labels = []\n","        \n","        for jj in batch_idxs:\n","            img = plt.imread(training_path + filenames_t[jj])\n","            img = cv2.resize(img, (h, w), cv2.INTER_NEAREST)\n","            inputs.append(img)\n","            \n","            label_img = cv2.imread(segmented_path +filenames_s[jj], cv2.IMREAD_UNCHANGED)            \n","            road_mask = (label_img == road_idx).astype(np.uint8)\n","            road_mask = cv2.resize(road_mask, (h, w), cv2.INTER_NEAREST)\n","            labels.append(road_mask)\n","         \n","        inputs = np.stack(inputs, axis=2)\n","        inputs = torch.tensor(inputs).transpose(0, 2).transpose(1, 3)\n","        labels = torch.tensor(labels)\n","        #print('label ', labels.shape)\n","        \n","        yield inputs, labels"]},{"cell_type":"markdown","metadata":{},"source":["## IoU functions"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T14:32:06.462168Z","iopub.status.busy":"2024-01-11T14:32:06.461905Z","iopub.status.idle":"2024-01-11T14:32:06.476716Z","shell.execute_reply":"2024-01-11T14:32:06.475970Z","shell.execute_reply.started":"2024-01-11T14:32:06.462146Z"},"trusted":true},"outputs":[],"source":["def intersection_over_union(pred_mask, true_mask):\n","    intersection = torch.logical_and(pred_mask, true_mask).sum().item()\n","    union = torch.logical_or(pred_mask, true_mask).sum().item()\n","\n","    iou = intersection / union if union > 0 else 0.0\n","    return iou\n","\n","def mean_iou(predictions, targets, num_classes):\n","    class_iou = [0] * num_classes\n","    \n","    for class_idx in range(num_classes):\n","        pred_mask = (predictions == class_idx)\n","        true_mask = (targets == class_idx)\n","        class_iou[class_idx] = intersection_over_union(pred_mask, true_mask)\n","\n","    mean_iou_value = sum(class_iou) / num_classes\n","    \n","    return mean_iou_value\n","\n","\n","def calculate_mIoU(model, inputs, labels, device, num_classes):\n","    model.eval()\n","\n","    inputs = inputs.to(device)\n","    labels = labels.to(device)\n","\n","    with torch.no_grad():\n","        outputs = model(inputs)\n","        predictions = torch.argmax(outputs, dim=1)\n","\n","        batch_iou = mean_iou(predictions, labels, num_classes)\n","        mIoU = batch_iou\n","    return mIoU\n","\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_4qD8VBah2K2"},"source":["## Define the class weights"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{},"colab_type":"code","execution":{"iopub.execute_input":"2024-01-11T14:32:06.477951Z","iopub.status.busy":"2024-01-11T14:32:06.477692Z","iopub.status.idle":"2024-01-11T14:32:06.490317Z","shell.execute_reply":"2024-01-11T14:32:06.489524Z","shell.execute_reply.started":"2024-01-11T14:32:06.477929Z"},"id":"GmnNEeMHiSU2","trusted":true},"outputs":[],"source":["def get_class_weights(pipe,num_classes, c=1.02):\n","    _, labels = next(pipe)\n","    all_labels = labels.flatten()\n","    each_class = np.bincount(all_labels, minlength=num_classes)\n","    prospensity_score = each_class / len(all_labels)\n","    class_weights = 1 / (np.log(c + prospensity_score))\n","    return class_weights"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{},"colab_type":"code","execution":{"iopub.execute_input":"2024-01-11T14:32:06.491557Z","iopub.status.busy":"2024-01-11T14:32:06.491287Z","iopub.status.idle":"2024-01-11T14:32:06.499877Z","shell.execute_reply":"2024-01-11T14:32:06.499122Z","shell.execute_reply.started":"2024-01-11T14:32:06.491535Z"},"id":"qHBoLmadmrA_","trusted":true},"outputs":[],"source":["pipe = loader('/kaggle/input/camvid-segmap/CamVid/train/', '/kaggle/input/camvid-segmap/CamVid/trainannot/', batch_size='all')\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T14:32:06.501086Z","iopub.status.busy":"2024-01-11T14:32:06.500821Z","iopub.status.idle":"2024-01-11T14:32:41.805708Z","shell.execute_reply":"2024-01-11T14:32:41.804686Z","shell.execute_reply.started":"2024-01-11T14:32:06.501065Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_26/3767593591.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /usr/local/src/pytorch/torch/csrc/utils/tensor_new.cpp:245.)\n","  labels = torch.tensor(labels)\n"]},{"name":"stdout","output_type":"stream","text":["[1.87286398 3.46680241]\n"]}],"source":["class_weights = get_class_weights(pipe,2)\n","print(class_weights)\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wwnNuFIfhsXm"},"source":["## Define the Hyperparameters"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{},"colab_type":"code","execution":{"iopub.execute_input":"2024-01-11T15:05:51.637777Z","iopub.status.busy":"2024-01-11T15:05:51.636954Z","iopub.status.idle":"2024-01-11T15:05:51.645318Z","shell.execute_reply":"2024-01-11T15:05:51.644441Z","shell.execute_reply.started":"2024-01-11T15:05:51.637743Z"},"id":"DI9425iz7thP","trusted":true},"outputs":[],"source":["lr = 5e-4\n","batch_size = 10\n","\n","criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor(class_weights).to(device))\n","\n","optimizer = torch.optim.Adam(enet.parameters(), \n","                             lr=lr,\n","                             weight_decay=2e-4)\n","scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n","\n","\n","epochs = 2000\n","save_every = 100\n","eval_every = 50\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CFIdlVWviBYl"},"source":["## Training loop"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"colab_type":"code","execution":{"iopub.execute_input":"2024-01-11T15:05:54.492845Z","iopub.status.busy":"2024-01-11T15:05:54.492132Z","iopub.status.idle":"2024-01-11T15:05:54.508400Z","shell.execute_reply":"2024-01-11T15:05:54.507363Z","shell.execute_reply.started":"2024-01-11T15:05:54.492812Z"},"id":"WQ6XJzl6Ta1_","outputId":"a3f62522-391d-4e05-f138-11c78a0d90cf","trusted":true},"outputs":[],"source":["train_losses = []\n","eval_losses = []\n","eval_acc = []\n","test_losses = []\n","test_acc = []\n","\n","batch_size = 10\n","bc_train = 367 // batch_size # mini_batch train\n","bc_eval = 101 // batch_size  # mini_batch validation\n","bc_test = 233 // batch_size\n","\n","\n","# Define pipeline objects\n","pipe = loader('/kaggle/input/camvid-segmap/CamVid/train/', '/kaggle/input/camvid-segmap/CamVid/trainannot/', batch_size)\n","eval_pipe = loader('/kaggle/input/camvid-segmap/CamVid/val/', '/kaggle/input/camvid-segmap/CamVid/valannot/', batch_size)\n","\n","\n","# Train loop\n","def train (model,epochs, pipe, eval_pipe, criterion, optimizer, scheduler, device):\n","    for e in range(1, epochs+1):\n","\n","        if (epochs<60):\n","            for param in enet.decoder.parameters():\n","                param.requires_grad = False\n","    \n","        train_loss = 0\n","        print ('-'*15,'Epoch %d' % e, '-'*15)\n","    \n","        enet.train()\n","    \n","        for _ in tqdm(range(bc_train)):\n","            X_batch, mask_batch = next(pipe)\n","        \n","            # assign data to cpu/gpu\n","            X_batch, mask_batch = X_batch.to(device), mask_batch.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            out = enet(X_batch.float())\n","            #print(mask_batch.shape)\n","            #print( 'pred ',out.shape)\n","        \n","            # loss calculation\n","            loss = criterion(out, mask_batch.long())\n","            # update weights\n","            loss.backward()\n","            optimizer.step()\n","            train_loss += loss.item()\n","        \n","        train_losses.append(train_loss/batch_size)\n","    \n","    \n","        with torch.no_grad():\n","            enet.eval()\n","            \n","            eval_loss = 0\n","            cum_eval_iou =0\n","        \n","            # Validation loop\n","            for _ in tqdm(range(bc_eval)):\n","                inputs, labels = next(eval_pipe)\n","                \n","                inputs, labels = inputs.to(device), labels.to(device)\n","                    \n","                out = enet(inputs)\n","                loss = criterion(out, labels.long())\n","                eval_loss += loss.item()\n","            \n","                cum_eval_iou += calculate_mIoU(enet, inputs, labels, device, 2)            \n","   \n","        eval_losses.append(eval_loss/batch_size)\n","        eval_acc.append(cum_eval_iou/batch_size)\n","        print ('Epoch {}/{}...'.format(e, epochs),\n","                'train_Loss {:6f}'.format(train_losses[-1]),\n","                'eval_Loss {:6f}'.format(eval_losses[-1]),\n","                'eval_acc {:6f}'.format(eval_acc[-1]))\n","        \n","        scheduler.step(eval_loss/bc_eval)\n","        if e % save_every == 0:\n","            checkpoint = {\n","            'epochs' : e,\n","            'state_dict' : enet.state_dict(),\n","            'train_error' :train_losses,\n","            'val_error' : eval_losses,\n","            'iou_trend' : eval_acc,\n","            \n","            }\n","            torch.save(checkpoint, './ckpt-enet-camvid-{}-{}.pth'.format(e, train_loss))\n","            print ('Model saved!')\n","            \n","        print(f'current learning rate: {optimizer.param_groups[0][\"lr\"]}')\n","        \n","        print ('Epoch {}/{}...'.format(e, epochs),\n","           'Total Mean train Loss: {:6f}'.format(sum(train_losses) / e))\n","    return train_losses, eval_losses, eval_acc"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T15:05:56.831873Z","iopub.status.busy":"2024-01-11T15:05:56.831181Z","iopub.status.idle":"2024-01-11T15:07:38.090899Z","shell.execute_reply":"2024-01-11T15:07:38.089804Z","shell.execute_reply.started":"2024-01-11T15:05:56.831843Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------- Epoch 1 ---------------\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 36/36 [00:36<00:00,  1.02s/it]\n","100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/2000... train_Loss 2.138586 eval_Loss 13.067693 eval_acc 0.151923\n","current learning rate: 5e-08\n","Epoch 1/2000... Total Mean train Loss: 2.138586\n","--------------- Epoch 2 ---------------\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 36/36 [00:36<00:00,  1.01s/it]\n","100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/2000... train_Loss 2.147134 eval_Loss 13.495261 eval_acc 0.154634\n","current learning rate: 5e-08\n","Epoch 2/2000... Total Mean train Loss: 2.142860\n","--------------- Epoch 3 ---------------\n"]},{"name":"stderr","output_type":"stream","text":[" 22%|██▏       | 8/36 [00:09<00:31,  1.13s/it]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_losses, eval_losses, eval_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43menet\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_pipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[33], line 31\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, epochs, pipe, eval_pipe, criterion, optimizer, scheduler, device)\u001b[0m\n\u001b[1;32m     28\u001b[0m enet\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(bc_train)):\n\u001b[0;32m---> 31\u001b[0m     X_batch, mask_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# assign data to cpu/gpu\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     X_batch, mask_batch \u001b[38;5;241m=\u001b[39m X_batch\u001b[38;5;241m.\u001b[39mto(device), mask_batch\u001b[38;5;241m.\u001b[39mto(device)\n","Cell \u001b[0;32mIn[9], line 32\u001b[0m, in \u001b[0;36mloader\u001b[0;34m(training_path, segmented_path, batch_size, h, w)\u001b[0m\n\u001b[1;32m     30\u001b[0m inputs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(inputs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     31\u001b[0m inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(inputs)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#print('label ', labels.shape)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m inputs, labels\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["train_losses, eval_losses, eval_acc = train(enet,epochs, pipe, eval_pipe, criterion, optimizer, scheduler, device )"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T15:08:45.391715Z","iopub.status.busy":"2024-01-11T15:08:45.390967Z","iopub.status.idle":"2024-01-11T15:08:45.704541Z","shell.execute_reply":"2024-01-11T15:08:45.703583Z","shell.execute_reply.started":"2024-01-11T15:08:45.391682Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Text(0.5, 1.0, 'Training and Validation losses trend')"]},"execution_count":35,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["\n","plt.plot(train_losses, label='train_losses')\n","plt.plot(eval_losses, label = 'eval_losses')\n","plt.legend(frameon = True)\n","plt.title('Training and Validation losses trend')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T14:33:13.070514Z","iopub.status.idle":"2024-01-11T14:33:13.070869Z","shell.execute_reply":"2024-01-11T14:33:13.070713Z","shell.execute_reply.started":"2024-01-11T14:33:13.070698Z"},"trusted":true},"outputs":[],"source":["test_pipe = loader('/kaggle/input/camvid-segmap/CamVid/test/', '/kaggle/input/camvid-segmap/CamVid/testannot/', batch_size)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T14:33:13.071803Z","iopub.status.idle":"2024-01-11T14:33:13.072280Z","shell.execute_reply":"2024-01-11T14:33:13.072043Z","shell.execute_reply.started":"2024-01-11T14:33:13.072022Z"},"trusted":true},"outputs":[],"source":["\n","def test_model(model, epochs,testloaders, criterion, optimizer, scheduler,device):\n","    \n","    for e in range(1,epochs+1):\n","        enet.to(device)\n","        with torch.no_grad():\n","            enet.eval()\n","            \n","            test_loss = 0\n","        cum_test_iou = 0\n","        # test loop\n","        for _ in tqdm(range(bc_test)):\n","            inputs, labels = next(test_pipe)\n","                \n","            inputs, labels = inputs.to(device), labels.to(device)\n","                    \n","            out = enet(inputs)\n","            loss = criterion(out, labels.long())\n","            test_loss += loss.item()\n","            cum_test_iou += calculate_IoU(enet, inputs, labels, device)\n","          \n","            #print ('testLoss {:6f}'.format(test_loss))\n","        \n","        test_losses.append(test_loss/bc_test)\n","        test_acc.append(cum_test_iou/bc_test)\n","        \n","        print ('Epoch {}/{}...'.format(e, epochs),\n","                'eval_Loss {:6f}'.format(test_loss),\n","                'test_acc{:4f}'.format(test_acc[-1]))\n","    return test_losses, test_acc\n","        \n","      "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T14:33:13.073345Z","iopub.status.idle":"2024-01-11T14:33:13.073757Z","shell.execute_reply":"2024-01-11T14:33:13.073584Z","shell.execute_reply.started":"2024-01-11T14:33:13.073563Z"},"trusted":true},"outputs":[],"source":["test_losses, test_acc = test_model(enet, epochs,test_pipe, criterion, optimizer, scheduler, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T14:33:13.075177Z","iopub.status.idle":"2024-01-11T14:33:13.075635Z","shell.execute_reply":"2024-01-11T14:33:13.075419Z","shell.execute_reply.started":"2024-01-11T14:33:13.075399Z"},"trusted":true},"outputs":[],"source":["plt.plot(train_losses, label='train_losses')\n","plt.plot(eval_losses, label='valid_losses')\n","\n","# Move the test_losses tensor to the CPU before plotting\n","# Convert the test_losses list to a NumPy array before plotting\n","plt.plot(np.array(test_losses), label='test_losses')\n","\n","plt.legend(frameon=True)\n","plt.title('Training, Validation, and Test Losses trend')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T14:33:13.076916Z","iopub.status.idle":"2024-01-11T14:33:13.077364Z","shell.execute_reply":"2024-01-11T14:33:13.077142Z","shell.execute_reply.started":"2024-01-11T14:33:13.077122Z"},"trusted":true},"outputs":[],"source":["\n","plt.plot(eval_acc, label = 'val_accuracy')\n","plt.plot(test_acc, label = 'test_accuracy')\n","plt.xlabel('epochs')\n","plt.ylabel('IoU')\n","plt.legend(frameon= True)\n","plt.title('Validation and Test Accuracy trend')\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"bdp5YLb0ibFO"},"source":["## Infer using the trained model"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"cspEQPgEKVvg"},"source":["Get the PreTrained ENet model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T14:33:13.080095Z","iopub.status.idle":"2024-01-11T14:33:13.080454Z","shell.execute_reply":"2024-01-11T14:33:13.080302Z","shell.execute_reply.started":"2024-01-11T14:33:13.080286Z"},"trusted":true},"outputs":[],"source":["def decode_segmap(image):\n","    road_color = [255, 0, 255]  # Magenta for road\n","    non_road_color = [255, 0, 0]  # Red for non-road\n","\n","    # Create an RGB image with all pixels set to the non-road color\n","    rgb = np.ones((image.shape[0], image.shape[1], 3), dtype=np.uint8) * non_road_color\n","\n","    # Set pixels belonging to the road to the road color\n","    rgb[image == 1] = road_color\n","\n","    return rgb"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T14:33:13.081787Z","iopub.status.idle":"2024-01-11T14:33:13.082106Z","shell.execute_reply":"2024-01-11T14:33:13.081965Z","shell.execute_reply.started":"2024-01-11T14:33:13.081951Z"},"trusted":true},"outputs":[],"source":["def show_images(images, in_row=True):\n","    '''\n","    Helper function to show 3 images\n","    '''\n","    total_images = len(images)\n","\n","    rc_tuple = (1, total_images)\n","    if not in_row:\n","        rc_tuple = (total_images, 1)\n","    \n","    #figure = plt.figure(figsize=(20, 10))\n","    for ii in range(len(images)):\n","        plt.subplot(*rc_tuple, ii+1)\n","        plt.title(images[ii][0])\n","        plt.axis('off')\n","        plt.imshow(images[ii][1])\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T14:33:13.083089Z","iopub.status.idle":"2024-01-11T14:33:13.083435Z","shell.execute_reply":"2024-01-11T14:33:13.083287Z","shell.execute_reply.started":"2024-01-11T14:33:13.083271Z"},"trusted":true},"outputs":[],"source":["h = 512\n","w = 512\n","\n","checkpoint = torch.load('')\n","    \n","# Assuming the dataset is camvid\n","enet = ENet(2)\n","enet = enet.to(device)\n","state_dict = torch.load('./ckpt-enet-camvid.pth')['state_dict']\n","enet.load_state_dict(state_dict)\n","\n","tmg_ = plt.imread(image_path)\n","tmg_ = cv2.resize(tmg_, (h, w), cv2.INTER_NEAREST)\n","tmg = torch.tensor(tmg_).unsqueeze(0).float()\n","tmg = tmg.transpose(2, 3).transpose(1, 2)\n","tmg = tmg.to(device)\n","\n","with torch.no_grad():\n","    out1 = enet(tmg.float()).squeeze(0)\n","    \n","b_ = out1.data.max(0)[1].cpu().numpy()\n","\n","decoded_segmap = decode_segmap(b_)\n","\n","smg_ = Image.open('/content/training/semantic/' + fname)\n","smg_ = cv2.resize(np.array(smg_), (512, 512), cv2.INTER_NEAREST)\n","gt_path = FLAGS.image_path.replace('test','testannot') \n","gt = plt.imread(gt_path)\n","gt = cv2.resize(gt, (h, w), cv2.INTER_NEAREST)\n","\n","images = {\n"," 0 : ['Input Image', tmg_],\n"," 1 : ['Predicted Segmentation', decoded_segmap],\n"," 2 : ['ground truth', gt]\n","}\n","\n","show_images(images)\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_YI65NDYmr7h"},"source":["## Save the model checkpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","execution":{"iopub.status.busy":"2024-01-11T14:33:13.084631Z","iopub.status.idle":"2024-01-11T14:33:13.084961Z","shell.execute_reply":"2024-01-11T14:33:13.084814Z","shell.execute_reply.started":"2024-01-11T14:33:13.084794Z"},"id":"WjUZDGfU5F8X","trusted":true},"outputs":[],"source":["# Save the parameters\n","checkpoint = {\n","    'epochs' : e,\n","    'state_dict' : enet.state_dict()\n","\n","}\n","torch.save(checkpoint, 'ckpt-enet-camvid-1.pth')"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"51UgRcNYmwCc"},"source":["## Save the entire model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","execution":{"iopub.status.busy":"2024-01-11T14:33:13.086638Z","iopub.status.idle":"2024-01-11T14:33:13.086982Z","shell.execute_reply":"2024-01-11T14:33:13.086827Z","shell.execute_reply.started":"2024-01-11T14:33:13.086805Z"},"id":"sQVVoXhn5oun","trusted":true},"outputs":[],"source":["# Save the model\n","torch.save(enet, '/model.pt')"]},{"cell_type":"markdown","metadata":{},"source":["## IoU Calculation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T14:33:13.088063Z","iopub.status.idle":"2024-01-11T14:33:13.088404Z","shell.execute_reply":"2024-01-11T14:33:13.088254Z","shell.execute_reply.started":"2024-01-11T14:33:13.088238Z"},"trusted":true},"outputs":[],"source":["\n","\n","#def mean_iou(predictions, targets, num_classes):\n","    #class_iou = [0] * num_classes\n","    \n","    #for class_idx in range(num_classes):\n","        #pred_mask = (predictions == class_idx)\n","        #true_mask = (targets == class_idx)\n","        #class_iou[class_idx] = intersection_over_union(pred_mask, true_mask)\n","\n","    #mean_iou_value = sum(class_iou) / num_classes\n","    \n","    #return mean_iou_value"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-11T14:33:13.089922Z","iopub.status.idle":"2024-01-11T14:33:13.090259Z","shell.execute_reply":"2024-01-11T14:33:13.090092Z","shell.execute_reply.started":"2024-01-11T14:33:13.090077Z"},"trusted":true},"outputs":[],"source":["validation_path = ''\n","segmentation_path = ''\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","inputs, labels = pipe(validation_path, segmentation_path)\n","IoU_eval = calculate_mIoU(enet, inputs, labels, device, 2)\n","print(\"road IoU on camvid\", mIoU_eval)\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"ENet - Real Time Semantic Segmentation.ipynb","provenance":[],"toc_visible":true,"version":"0.3.2"},"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4289690,"sourceId":7381359,"sourceType":"datasetVersion"}],"dockerImageVersionId":30636,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
